# Better Prompts MCP 服务使用说明

## 概述

Better Prompts 是一个 MCP (Model Context Protocol) 服务，用于从文章中萃取理论方法论并存储到知识库中，然后根据用户输入自动检索相关方法论来构建增强的提示词。

## 功能特性

### 1. 萃取工具 (extract_methodology)
- 支持文本内容和 URL 链接输入
- 自动提取网页正文内容
- 使用 AI 从内容中萃取可操作的方法论
- 支持本地和云端两种存储方式

### 2. 提示增强工具 (enhance_prompt)  
- 根据用户输入从知识库检索相关方法论
- 结合方法论生成增强的提示词
- 提供更专业、更具指导性的提示内容

## 安装配置

### 1. 环境准备

```bash
# 进入项目目录
cd better_prompts

# 创建虚拟环境并安装依赖
uv venv
source .venv/bin/activate
uv pip install -e .
```

### 2. 环境变量配置

将 `env_example.txt` 复制为 `.env` 并配置相应参数：

```bash
cp env_example.txt .env
```

#### 基础配置
```
# 知识库存储方式: local/cloud
KNOWLEDGE_STORAGE=local

# 大模型API配置
LLM_API_BASE=https://api.openai.com/v1
LLM_API_KEY=your_api_key_here
LLM_MODEL_NAME=gpt-3.5-turbo
```

#### 本地存储配置
如果选择本地存储 (KNOWLEDGE_STORAGE=local)，需要：

1. **安装 Ollama**：
   ```bash
   # macOS
   brew install ollama
   
   # 启动 Ollama
   ollama serve
   
   # 安装嵌入模型
   ollama pull nomic-embed-text
   ```

2. **Milvus Lite** 已包含在依赖中，会自动创建本地数据库文件

#### 云端存储配置  
如果选择云端存储 (KNOWLEDGE_STORAGE=cloud)，需要配置 Dify 参数：

```
DIFY_BASE_URL=http://dify.dulicode.com/v1
DIFY_API_KEY=your_dify_api_key
DIFY_DATASET_ID=your_dataset_id
DIFY_DOCUMENT_ID=your_document_id
```

### 3. Claude Desktop 配置

编辑 Claude Desktop 配置文件：
```bash
# macOS
code ~/Library/Application\ Support/Claude/claude_desktop_config.json
```

添加服务配置（参考 `claude_desktop_config_example.json`）：

```json
{
    "mcpServers": {
        "better_prompts": {
            "command": "uv",
            "args": [
                "--directory", 
                "/绝对路径/到/better_prompts",
                "run",
                "python",
                "-m", 
                "mcp_server_better_prompts"
            ],
            "env": {
                "KNOWLEDGE_STORAGE": "local",
                "LLM_API_BASE": "https://api.openai.com/v1", 
                "LLM_API_KEY": "your_api_key_here",
                "LLM_MODEL_NAME": "gpt-3.5-turbo"
            }
        }
    }
}
```

重启 Claude Desktop 即可使用。

## 使用方法

### 1. 萃取方法论

#### 从文本萃取
```
请帮我萃取以下内容中的方法论：

[这里粘贴要萃取的文本内容]
```

#### 从 URL 萃取  
```
请帮我萃取这个网页中的方法论：
https://example.com/article
```

### 2. 增强提示词

```
请帮我优化这个提示词：

我想写一篇关于产品营销的文案
```

系统会自动：
1. 从知识库检索相关的营销方法论
2. 结合方法论生成增强的提示词
3. 返回更专业、更具指导性的提示内容

## 工作流程

### 萃取流程
1. 用户输入文本或 URL
2. 如果是 URL，自动提取网页正文
3. 调用大模型萃取方法论
4. 存储到配置的知识库（本地/云端）
5. 返回萃取结果和存储状态

### 增强流程  
1. 用户输入原始提示词
2. 从知识库检索相关方法论（默认前3个）
3. 结合方法论调用大模型生成增强提示
4. 返回增强后的提示词

## 技术架构

- **MCP 协议**: 基于标准 MCP 协议实现
- **本地存储**: Milvus Lite + Ollama nomic-embed-text
- **云端存储**: Dify 知识库 API
- **内容提取**: readabilipy + markdownify  
- **大模型**: 支持 OpenAI 兼容的 API

## 注意事项

1. **API 配置**: 确保大模型 API 密钥正确配置
2. **本地依赖**: 使用本地存储需要确保 Ollama 服务正常运行
3. **网络连接**: URL 萃取功能需要网络连接
4. **存储选择**: 根据需求选择本地或云端存储方式

## 故障排除

### 常见问题

1. **Milvus 向量数据库错误**
   - 如果出现 `'list' object has no attribute 'verify'` 错误，已在最新版本中修复
   - 如果遇到 NumPy 版本兼容性警告，可以忽略，不影响功能使用
   - 重新安装服务：`uv pip install -e . --force-reinstall`

2. **Ollama 连接失败**
   - 确保 Ollama 服务已启动：`ollama serve`
   - 确认模型已安装：`ollama list | grep nomic-embed-text`

3. **Dify API 调用失败**  
   - 检查 API 密钥和端点配置
   - 确认知识库 ID 和文档 ID 正确

4. **大模型 API 调用失败**
   - 检查 API 密钥和基础 URL
   - 确认模型名称正确

5. **MCP 服务无法启动**
   - 检查 Claude Desktop 配置文件路径
   - 确认环境变量配置正确
