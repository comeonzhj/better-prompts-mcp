学习参考项目路径下`For Server Developers-python.md`文档中的代码机制，它是一种叫做 MCP 的协议，这个协议可以根据用户提出的需求自动为大语言模型构建上下文。

确保你学会了 MCP 的构建方法，在此基础上，为我构建以下这个 MCP 服务。

## MCP 概述

这是一个自动帮助用户从文章中萃取理论，存储到向量数据库（下称“知识库”），根据用户的输入自动从知识库中调用方法论，构建更增强提示词的 MCP 服务，名字叫“better_prompts”。

## 工具及功能

### 萃取Tool

#### 工具描述

当用户需要萃取理论时，使用这个工具。工具接收一段文本或者 url 链接，使用大模型 API 加工后萃取其中的理论，存储到知识库中，告知用户存取结果和内容。

#### 工具作用机制

1. 识别到用户输入中包含类似“萃取”、“存一下方法论”时触发。

	- 如果用户传过来的信息是url，则对当前网页的正文内容进行提取。实现逻辑参考路径下`fetch`项目的实现（它本身也是一个 MCP 服务）

	- 如果用户传过来的信息不是 URL，则直接使用用户传来的文本内容。

2. 把上个环节处理完的内容，发送给大模型，系统提示词见`萃取.md`，用户提示词使用`待萃取方法论的文章：\n<content>\n${content}\n</content>`

3. 等待模型返回，把返回的内容存储到知识库中，可选两种存储方式

	- 两种方式如何选择取决于用户在环境变量中的配置：local/cloud

	- 本地存储：

		- 条件：本机安装了 Milvus Lite Python 库，使用 Ollama 部署了向量模型 nomic-embed-text:latest

		- 在网上检索一下这两个项目对应的官方文档，在本地写一个数据库信息向量化存储的实现

	- 云端存储：

		- 条件：在 Dify 云端配置了知识库

		- 调用方式参考路径下的`向知识库添加文本段落API.md`

4. 给用户返回萃取的理论和知识库存储结果

### P增强Tool

#### 工具描述

当用户使用 AI 大模型时，对用户的原始输入进行提示增强。工具接收一段文本输入，使用大模型 API 加工后获得增强的提示，返回增强的提示。

#### 工具作用机制

1. 识别到用户输入中包含类似“增强”或“优化提示”时触发。

2. 使用用户的输入，在知识库中检索，获得匹配的前三个段落：

	- 如果用户使用本地存储，检索 Milvus Lite 查询的策略，实现功能

	- 如果用户使用云端存储，调用方式参考路径下的`检索知识库API.mdx`

3. 将检索到的段落与用户的原始提示词一并发送给大模型 API，构造增强提示，向大模型请求的系统提示词见`make_prompt.md`,用户提示词使用`用户需求：\n<user_query>\n${user_input}\n</user_query>\n可选方法论支持\n<methodology>\n${results}\n</methodology>`

4. 向客户端返回大模型 API 返回的结果

### 变量调用

使用环境变量的形式存储调用所有可配置参数，可能的参数：

- 知识库存储方式：本地/云端

- 大模型 API：base_url、model_name、API_Key

- Dify 知识库信息（如果选择云端）：base_url、API_Key、dataset_id、document_id

## 注意事项

- 确保你理解了 MCP 服务的机制和开发方式

- 以上两个 Tool 包含的功能可能过于复杂，你可以把它拆成更多子工具，但确保每个工具返回的信息，能够被客户端理解如何应用及与其他工具的关系（调用顺序、输入输出依赖）

- 关于 MCP 服务的补充：只需将 MCP 服务的配置参数填写到支持 MCP 的客户端，即可在需要工具时由客户端通过`command`启动服务，同时读取其中的环境变量用来完成调用。